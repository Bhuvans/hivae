{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import parser_arguments\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import loglik_models_missing_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser_arguments.getArgs(sys.argv[1:])\n",
    "args = parser_arguments.getArgs_jupyter_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./Saved_Networks/'+args.save_file):\n",
    "    os.makedirs('./Saved_Networks/'+args.save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_file_name = './Saved_Networks/' + args.save_file + '/' + args.save_file + '.ckpt'\n",
    "log_file_name = './Saved_Networks' + args.save_file + '/log_file_' + args.save_file + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 200, 'epochs': 5, 'perp': 10, 'train': 1, 'display': 1, 'save': 1000, 'restore': 0, 'plot': 1, 'dim_latent_s': 4, 'dim_latent_z': 2, 'dim_latent_y': 3, 'dim_latent_y_partition': [], 'miss_perentage_train': 0.0, 'miss_percentage_test': 0.0, 'model_name': 'model_new', 'save_file': 'breast_data_zdim5_ydim10_4images_', 'data_file': './Breast/data.csv', 'types_file': './Breast/data_types.csv', 'miss_file': './Breast/Missing40_4.csv', 'true_miss_file': ''}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read functions.read_data \n",
    "# Inputs: data_file, types_file, miss_file, true_miss_file\n",
    "\n",
    "nan_definition = [-9999., 'nan']\n",
    "# Read types of data from types_file\n",
    "data_types = pd.read_csv(args.types_file)\n",
    "types_dict = data_types.to_dict('records')\n",
    "\n",
    "\n",
    "# Read data from the input file, compute the true missing mask and replace the true missing values with placeholder value\n",
    "column_names = [item['type']+'_'+str(i) for i, item in enumerate(types_dict)]\n",
    "\n",
    "data_df = pd.read_csv(args.data_file, header=None, na_values=nan_definition, names=column_names, dtype=np.float64)\n",
    "filler_value = dict()\n",
    "for col in column_names:\n",
    "    if 'cat' in col or 'ordinal' in col: \n",
    "        filler_value[col] = np.unique(data_df[col])[0]\n",
    "    else: \n",
    "        filler_value[col] = 0.0\n",
    "        \n",
    "data_df_filled = np.array(data_df.fillna(value=filler_value))\n",
    "\n",
    "true_miss_mask = pd.notna(data_df).astype(int)\n",
    "\n",
    "# Construct the data matrices\n",
    "data_complete = []\n",
    "for i in range(np.shape(data_df_filled)[1]):\n",
    "    if types_dict[i]['type']=='cat':\n",
    "        cat_data = [int(x) for x in data_df_filled[:, i]]\n",
    "        _, indexes = np.unique(cat_data, return_inverse=True)\n",
    "        # Transform categories to a vector of 0:n_categories\n",
    "        new_categories = np.arange(int(types_dict[i]['dim']))\n",
    "        cat_data = new_categories[indexes]\n",
    "        # Create one-hot encoding for the categories \n",
    "        temp = np.zeros([np.shape(data_df_filled)[0], len(new_categories)])\n",
    "        temp[np.arange(np.shape(data_df_filled)[0]), cat_data] = 1\n",
    "        data_complete.append(temp)\n",
    "    elif types_dict[i]['type']=='ordinal':\n",
    "        cat_data = [int(x) for x in data_df_filled[:, i]]\n",
    "        _, indexes = np.unique(cat_data, return_inverse=True)\n",
    "        # Transform categories to a vector of 0:n_categories \n",
    "        new_categories = np.arange(int(types_dict[i]['dim']))\n",
    "        cat_data = new_categories[indexes]\n",
    "        # Create thermometer encoding for the categories \n",
    "        temp = np.zeros([np.shape(data_df_filled)[0], 1+len(new_categories)])\n",
    "        temp[:, 0] = 1\n",
    "        temp[np.arange(np.shape(data_df_filled)[0]), 1+cat_data] = -1\n",
    "        temp = np.cumsum(temp, 1)\n",
    "        data_complete.append(temp[:, :-1])\n",
    "    elif types_dict[i]['type'] == 'count':\n",
    "        if np.min(data_df_filled[:, i]) == 0:\n",
    "            temp = data_df_filled[:, i] + 1\n",
    "            data_complete.append(np.transpose([temp]))\n",
    "        else:\n",
    "            data_complete.append(np.transpose([data_df_filled[:, i]]))\n",
    "    else:\n",
    "        data_complete.append(np.transpose([data_df_filled[:, i]]))\n",
    "data = np.concatenate(data_complete, 1)\n",
    "\n",
    "# Read missing mask from .csv (contains positions of missing values)\n",
    "n_samples = np.shape(data)[0]\n",
    "n_variables = len(types_dict)\n",
    "miss_mask = np.ones([np.shape(data)[0], n_variables])\n",
    "# if there is no mask, assume all data is observed \n",
    "missing_positions = np.array(pd.read_csv(args.miss_file, header=None))       \n",
    "miss_mask[missing_positions[:,0]-1, missing_positions[:,1]-1] = 0\n",
    "\n",
    "# This cell returns: data, types_dict, miss_mask, true_miss_mask, n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an integer number of batches \n",
    "if args.batch_size > n_samples:\n",
    "    args.batch_size = n_samples\n",
    "# Get an integer number of batches \n",
    "n_batches = int(np.floor(np.shape(data)[0]/args.batch_size))\n",
    "# Compute the real miss_mask\n",
    "real_miss_mask = np.array(np.multiply(miss_mask, true_miss_mask)).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_index = 0\n",
    "normalized_data = []\n",
    "normalization_parameters = []\n",
    "for i in range(len(types_dict)):\n",
    "    missing_data, observed_data = tf.dynamic_partition(data[:,ftr_index:ftr_index+types_dict[i]['dim']], real_miss_mask[:,i], num_partitions=2)\n",
    "    condition_indices = tf.dynamic_partition(tf.range(tf.shape(data)[0]), real_miss_mask[:, i], num_partitions=2)\n",
    "\n",
    "    if types_dict[i]['type'] == 'real':\n",
    "        data_mean, data_var = tf.nn.moments(observed_data, 0)\n",
    "        data_var = tf.clip_by_value(data_var, 1e-6, 1e20) # Avoid zero values\n",
    "        norm_X = tf.nn.batch_normalization(observed_data, data_mean, data_var, offset=0.0, scale=1.0, variance_epsilon=1e-6)\n",
    "\n",
    "        normalized_data.append(tf.dynamic_stitch(condition_indices, [missing_data, norm_X]))\n",
    "        normalization_parameters.append([data_mean, data_var])\n",
    "\n",
    "    elif types_dict[i]['type'] == 'pos':\n",
    "        # we transform the log of the data to a gaussian with mean 0 and std 1\n",
    "        observed_data_log = tf.log(1.0+observed_data)\n",
    "        data_mean_log, data_var_log = tf.nn.moments(observed_data_log, 0)\n",
    "        data_var_log = tf.clip_by_value(data_var_log, 1e-6, 1e20) \n",
    "        norm_X = tf.nn.batch_normalization(observed_data_log, data_mean_log, data_var_log, offset=0.0, scale=1.0, variance_epsilon=1e-6)\n",
    "\n",
    "        normalized_data.append(tf.dynamic_stitch(condition_indices, [missing_data, norm_X]))\n",
    "        normalization_parameters.append([data_mean_log, data_var_log])\n",
    "\n",
    "    elif types_dict[i]['type'] == 'count':\n",
    "        aux_X = tf.math.log(observed_data)\n",
    "\n",
    "        normalized_data.append(tf.dynamic_stitch(condition_indices, [missing_data, aux_X]))\n",
    "        normalization_parameters.append([0.0, 1.0])\n",
    "\n",
    "    else:\n",
    "        normalized_data.append(data[:, ftr_index:ftr_index+types_dict[i]['dim']])\n",
    "        normalization_parameters.append([0.0, 1.0])\n",
    "    ftr_index = ftr_index + types_dict[i]['dim']\n",
    "\n",
    "normalized_data = tf.concat(normalized_data, 1)\n",
    "\n",
    "# This block returns normalized_data, normalization_parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimensionality of Y \n",
    "y_dim = args.dim_latent_y\n",
    "y_dim_partition = args.dim_latent_y_partition\n",
    "if y_dim_partition:\n",
    "    y_dim_output = np.sum(y_dim_partition)\n",
    "else:\n",
    "    y_dim_partition = y_dim*np.ones(len(types_dict), dtype=int)\n",
    "    y_dim_output = np.sum(y_dim_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_miss_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_dataset = tf.data.Dataset.from_tensor_slices((normalized_data, miss_mask, real_miss_mask)).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY AREA\n",
    "# *****************************************************************************************************************\n",
    "# Perform batch normalization of the data \n",
    "\n",
    "# normalizer = preprocessing.Normalization(input_shape=(data.shape[1],))\n",
    "# normalizer.adapt(data) # normalizer is now a tf.keras layer and can be used as the first layer of your NN model!!\n",
    "# mean = normalizer.mean.numpy()\n",
    "# variance = normalizer.variance.numpy()\n",
    "# *****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling_s(tf.keras.layers.Layer):\n",
    "    \"\"\" Uses Gumbel Softmax trick to sample s, the mixture component random variable that generates the latent variable z from a GMM. The Gumbel Softmax formulation \n",
    "    helps to implement the reparameterization trick for the discrete random variable 's' specified by activations, log_pi_aux. \n",
    "    \"\"\"\n",
    "    def __init__(self, tau):\n",
    "        super(Sampling_s, self).__init__()\n",
    "        self.tau = tau\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_activations = inputs\n",
    "        no_of_samples = tf.shape(input_activations)[0]\n",
    "        s_dim = tf.shape(input_activations)[1]\n",
    "        U = -tf.math.log(-tf.math.log(tf.random.uniform([no_of_samples, s_dim])))\n",
    "        samples_s = tf.nn.softmax((input_activations+U)/self.tau)\n",
    "        return samples_s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling_z_given_s(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, given the samples of s. The random variable z is assumed to follow a GMM.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5*z_log_var)*epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 92)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_enc_s (Dense)           (None, 4)            372         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 4)            0           layer_1_enc_s[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.clip_by_value (TFOpLambda)   (None, 4)            0           tf.nn.softmax[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.log (TFOpLambda)        (None, 4)            0           tf.clip_by_value[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sampling_s (Sampling_s)         (None, 4)            0           tf.math.log[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 96)           0           input_1[0][0]                    \n",
      "                                                                 sampling_s[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_logvar_enc_z (Dense)    (None, 2)            194         tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_mean_enc_z (Dense)      (None, 2)            194         tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.clip_by_value_1 (TFOpLambda) (None, 2)            0           layer_1_logvar_enc_z[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sampling_z_given_s (Sampling_z_ (None, 2)            0           layer_1_mean_enc_z[0][0]         \n",
      "                                                                 tf.clip_by_value_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 760\n",
      "Trainable params: 760\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the Encoder \n",
    "\n",
    "tau = 1.00\n",
    "no_of_features = normalized_data.shape[1]\n",
    "s_dim = args.dim_latent_s\n",
    "z_dim = args.dim_latent_z\n",
    "\n",
    "sample_s = Sampling_s(tau) # Create an object\n",
    "\n",
    "encoder_inputs = tf.keras.Input(shape=(no_of_features, ))\n",
    "log_pi = tf.keras.layers.Dense(units=s_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'enc_s')\n",
    "x = log_pi(encoder_inputs)\n",
    "log_pi_aux = tf.math.log(tf.clip_by_value(tf.nn.softmax(x), 1e-6, 1))\n",
    "\n",
    "s = sample_s(log_pi_aux)\n",
    "\n",
    "input_data_and_s = tf.concat([encoder_inputs, s], 1)\n",
    "mean_qz = tf.keras.layers.Dense(units=z_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'mean_enc_z')(input_data_and_s)\n",
    "log_var_qz = tf.keras.layers.Dense(units=z_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'logvar_enc_z')(input_data_and_s)\n",
    "\n",
    "# Avoid numerical problems\n",
    "log_var_qz = tf.clip_by_value(log_var_qz, -15.0, 15.0)\n",
    "    \n",
    "z = Sampling_z_given_s()([mean_qz, log_var_qz])\n",
    "\n",
    "encoder = tf.keras.Model(encoder_inputs, [log_pi_aux, s, mean_qz, log_var_qz, z], name='encoder')  # check for reuse functionality of some layers here ????????\n",
    "# encoder = tf.keras.Model(encoder_inputs, log_pi_aux, name='encoder')  # check for reuse functionality of some layers here ????????\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8675\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8349\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8257\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8201\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8159\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8127\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8102\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8082\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8066\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e81031b148>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "encoder.compile(optimizer=optimizer, loss=mse_loss_fn)\n",
    "encoder.fit(normalized_data, normalized_data[:, 0:4], batch_size=32, epochs=10)\n",
    "# Iterate over epochs.\n",
    "# for epoch in range(epochs):\n",
    "#     print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "#     # Iterate over the batches of the dataset.\n",
    "#     for step, x_batch_train in enumerate(train_dataset):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             reconstructed = encoder(x_batch_train)\n",
    "#             # Compute reconstruction loss\n",
    "#             loss = mse_loss_fn(x_batch_train[:, 0:4], reconstructed[0])\n",
    "#             loss += sum(encoder.losses)  # Add KLD regularization loss\n",
    "\n",
    "#         grads = tape.gradient(loss, encoder.trainable_weights)\n",
    "#         optimizer.apply_gradients(zip(grads, encoder.trainable_weights))\n",
    "\n",
    "#         loss_metric(loss)\n",
    "\n",
    "#         if step % 100 == 0:\n",
    "#             print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_partition(samples_y, types_list, y_dim_partition):\n",
    "    grouped_samples_y = []\n",
    "    partition_vector_cumsum = np.insert(np.cumsum(y_dim_partition), 0, 0)\n",
    "    for i in range(len(types_list)):\n",
    "        grouped_samples_y.append(samples_y[:, partition_vector_cumsum[i]:partition_vector_cumsum[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observed_data_layer(observed_data, missing_data, condition_indices, output_dim, name, bias):\n",
    "    #Train a layer with the observed data and reuse it for the missing data\n",
    "    output_layer = tf.keras.layers.Dense(units=output_dim, activation=None,\n",
    "                         kernel_initializer=tf.random_normal_initializer(stddev=0.05),name=name,use_bias=bias)\n",
    "    output_layer.trainable=True\n",
    "    obs_output = output_layer(observed_data)\n",
    "    \n",
    "    output_layer.trainable = False\n",
    "    miss_output = output_layer(missing_data) \n",
    "    #Join back the data\n",
    "    output = tf.dynamic_stitch(condition_indices, [miss_output,obs_output])\n",
    "    return output\n",
    "\n",
    "\n",
    "def theta_real_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i, reuse):\n",
    "    #Mean layer    \n",
    "    h2_mean = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=types_list[i]['dim'], name='layer_h2' + str(i), reuse=reuse, bias=False)\n",
    "    #Sigma Layer    \n",
    "    h2_sigma = observed_data_layer(observed_s, missing_s, condition_indices, output_dim=types_list[i]['dim'], name='layer_h2_sigma' + str(i), reuse=reuse, bias=False)\n",
    "    return [h2_mean, h2_sigma]\n",
    "\n",
    "def theta_pos_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i, reuse):\n",
    "    \n",
    "    #Mean layer\n",
    "    h2_mean = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=types_list[i]['dim'], name='layer_h2' + str(i), reuse=reuse, bias=False)\n",
    "    \n",
    "    #Sigma Layer\n",
    "    h2_sigma = observed_data_layer(observed_s, missing_s, condition_indices, output_dim=types_list[i]['dim'], name='layer_h2_sigma' + str(i), reuse=reuse, bias=False)\n",
    "    \n",
    "    return [h2_mean, h2_sigma]\n",
    "\n",
    "def theta_count_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i, reuse):\n",
    "    \n",
    "    #Lambda Layer    \n",
    "    h2_lambda = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=types_list[i]['dim'], name='layer_h2' + str(i), reuse=reuse, bias=False)\n",
    "    \n",
    "    return h2_lambda\n",
    "\n",
    "def theta_cat_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i):\n",
    "    \n",
    "    #Log pi layer, with zeros in the first value to avoid the identificability problem   \n",
    "    h2_log_pi_partial = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=int(types_list[i]['dim'])-1, name='layer_h2' + str(i), bias=False)\n",
    "    h2_log_pi = tf.concat([tf.zeros([nObs,1]), h2_log_pi_partial],1)\n",
    "    return h2_log_pi\n",
    "\n",
    "def theta_ordinal_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i):\n",
    "    \n",
    "    #Theta layer, Dimension of ordinal - 1\n",
    "#     print(observed_y.shape)\n",
    "    h2_theta = observed_data_layer(observed_s, missing_s, condition_indices, output_dim=int(types_list[i]['dim'])-1, name='layer_h2' + str(i), bias=False)\n",
    "    \n",
    "    #Mean layer, a single value\n",
    "    h2_mean = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=1, name='layer_h2_sigma' + str(i), bias=False)\n",
    "    \n",
    "    return [h2_theta, h2_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_estimation_from_ys(samples_y, samples_s, types_list, miss_list):\n",
    "    theta = []\n",
    "    # Independent yd -> Compute p(xd|yd)\n",
    "    for i, d in enumerate(samples_y):\n",
    "        # Partition the data in missing data(0) and observed data(1)\n",
    "        missing_y, observed_y = tf.dynamic_partition(d, miss_list[:, i], num_partitions=2)\n",
    "        missing_s, observed_s = tf.dynamic_partition(samples_s, miss_list[:, i], num_partitions=2)\n",
    "        condition_indices = tf.dynamic_partition(tf.range(tf.shape(d)[0]), miss_list[:, i], num_partitions=2)\n",
    "        nObs = tf.shape(observed_y)[0]\n",
    "        \n",
    "        # Different layer models for each type of variable\n",
    "        if types_list[i]['type']=='real':\n",
    "            params = theta_real_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "        \n",
    "        elif types_list[i]['type']=='pos':\n",
    "            params = theta_pos_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "            \n",
    "        elif types_list[i]['type']=='count':\n",
    "            params = theta_count_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "        \n",
    "        elif types_list[i]['type']=='cat':\n",
    "            params = theta_cat_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "            \n",
    "        elif types_list[i]['type']=='ordinal':\n",
    "            params = theta_ordinal_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "        theta.append(params)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_h1_ (Dense)               (None, 3)            9           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_10 (Sl (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 3)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_8 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_9 (Sli (None, 0)            0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_19 (TFOpLamb (2,)                 0           tf.__operators__.getitem_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (2,)                 0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_3 (TFOpLambd (2,)                 0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_5 (TFOpLambd (2,)                 0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_7 (TFOpLambd (2,)                 0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_9 (TFOpLambd (2,)                 0           tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_11 (TFOpLamb (2,)                 0           tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_13 (TFOpLamb (2,)                 0           tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_15 (TFOpLamb (2,)                 0           tf.__operators__.getitem_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_17 (TFOpLamb (2,)                 0           tf.__operators__.getitem_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_27 (TFOpLa [(None, 0), (None, 0 0           tf.__operators__.getitem_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_29 (Sl ()                   0           tf.compat.v1.shape_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_28 (TFOpLa [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (2,)                 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_11 (Sl ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_1 (TFOpLam [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition (TFOpLambd [(None, 3), (None, 3 0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_13 (Sl ()                   0           tf.compat.v1.shape_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_4 (TFOpLam [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_3 (TFOpLam [(None, 0), (None, 0 0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_15 (Sl ()                   0           tf.compat.v1.shape_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_7 (TFOpLam [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_6 (TFOpLam [(None, 0), (None, 0 0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_17 (Sl ()                   0           tf.compat.v1.shape_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_10 (TFOpLa [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_9 (TFOpLam [(None, 0), (None, 0 0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_19 (Sl ()                   0           tf.compat.v1.shape_9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_13 (TFOpLa [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_12 (TFOpLa [(None, 0), (None, 0 0           tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_21 (Sl ()                   0           tf.compat.v1.shape_11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_16 (TFOpLa [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_15 (TFOpLa [(None, 0), (None, 0 0           tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_23 (Sl ()                   0           tf.compat.v1.shape_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_19 (TFOpLa [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_18 (TFOpLa [(None, 0), (None, 0 0           tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_25 (Sl ()                   0           tf.compat.v1.shape_15[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_22 (TFOpLa [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_21 (TFOpLa [(None, 0), (None, 0 0           tf.__operators__.getitem_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_27 (Sl ()                   0           tf.compat.v1.shape_17[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_25 (TFOpLa [(None, 4), (None, 4 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_24 (TFOpLa [(None, 0), (None, 0 0           tf.__operators__.getitem_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_20 (TFOpLamb (2,)                 0           tf.dynamic_partition_27[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_9 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_20 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_27[0][0]    \n",
      "                                                                 tf.dynamic_partition_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_19 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_27[0][1]    \n",
      "                                                                 tf.dynamic_partition_28[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.range (TFOpLambda)           (None,)              0           tf.__operators__.getitem_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_2 (TFOpLambda)        (None, 7)            0           tf.dynamic_partition[0][0]       \n",
      "                                                                 tf.dynamic_partition_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 7)            0           tf.dynamic_partition[0][1]       \n",
      "                                                                 tf.dynamic_partition_1[0][1]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_1 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_4 (TFOpLambda)        (None, 4)            0           tf.dynamic_partition_3[0][0]     \n",
      "                                                                 tf.dynamic_partition_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (None, 4)            0           tf.dynamic_partition_3[0][1]     \n",
      "                                                                 tf.dynamic_partition_4[0][1]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_2 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_6 (TFOpLambda)        (None, 4)            0           tf.dynamic_partition_6[0][0]     \n",
      "                                                                 tf.dynamic_partition_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_5 (TFOpLambda)        (None, 4)            0           tf.dynamic_partition_6[0][1]     \n",
      "                                                                 tf.dynamic_partition_7[0][1]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_3 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_8 (TFOpLambda)        (None, 4)            0           tf.dynamic_partition_9[0][0]     \n",
      "                                                                 tf.dynamic_partition_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_7 (TFOpLambda)        (None, 4)            0           tf.dynamic_partition_9[0][1]     \n",
      "                                                                 tf.dynamic_partition_10[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_4 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_10 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_12[0][0]    \n",
      "                                                                 tf.dynamic_partition_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_9 (TFOpLambda)        (None, 4)            0           tf.dynamic_partition_12[0][1]    \n",
      "                                                                 tf.dynamic_partition_13[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_5 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_12 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_15[0][0]    \n",
      "                                                                 tf.dynamic_partition_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_11 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_15[0][1]    \n",
      "                                                                 tf.dynamic_partition_16[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_6 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_14 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_18[0][0]    \n",
      "                                                                 tf.dynamic_partition_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_13 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_18[0][1]    \n",
      "                                                                 tf.dynamic_partition_19[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_7 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_16 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_21[0][0]    \n",
      "                                                                 tf.dynamic_partition_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_15 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_21[0][1]    \n",
      "                                                                 tf.dynamic_partition_22[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_8 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_27[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_18 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_24[0][0]    \n",
      "                                                                 tf.dynamic_partition_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_17 (TFOpLambda)       (None, 4)            0           tf.dynamic_partition_24[0][1]    \n",
      "                                                                 tf.dynamic_partition_25[0][1]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_30 (Sl ()                   0           tf.compat.v1.shape_20[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_29 (TFOpLa [(None,), (None,)]   0           tf.range_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h29 (Dense)               (None, 1)            4           tf.concat_19[0][0]               \n",
      "                                                                 tf.concat_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.zeros (TFOpLambda)           (None, 2)            0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_2 (TFOpLam [(None,), (None,)]   0           tf.range[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_h20 (Dense)               (None, 9)            36          tf.dynamic_partition_1[0][1]     \n",
      "                                                                 tf.dynamic_partition_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma0 (Dense)         (None, 1)            7           tf.concat_1[0][0]                \n",
      "                                                                 tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_5 (TFOpLam [(None,), (None,)]   0           tf.range_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h21 (Dense)               (None, 9)            36          tf.dynamic_partition_4[0][1]     \n",
      "                                                                 tf.dynamic_partition_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma1 (Dense)         (None, 1)            4           tf.concat_3[0][0]                \n",
      "                                                                 tf.concat_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_8 (TFOpLam [(None,), (None,)]   0           tf.range_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h22 (Dense)               (None, 9)            36          tf.dynamic_partition_7[0][1]     \n",
      "                                                                 tf.dynamic_partition_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma2 (Dense)         (None, 1)            4           tf.concat_5[0][0]                \n",
      "                                                                 tf.concat_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_11 (TFOpLa [(None,), (None,)]   0           tf.range_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h23 (Dense)               (None, 9)            36          tf.dynamic_partition_10[0][1]    \n",
      "                                                                 tf.dynamic_partition_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma3 (Dense)         (None, 1)            4           tf.concat_7[0][0]                \n",
      "                                                                 tf.concat_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_14 (TFOpLa [(None,), (None,)]   0           tf.range_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h24 (Dense)               (None, 9)            36          tf.dynamic_partition_13[0][1]    \n",
      "                                                                 tf.dynamic_partition_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma4 (Dense)         (None, 1)            4           tf.concat_9[0][0]                \n",
      "                                                                 tf.concat_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_17 (TFOpLa [(None,), (None,)]   0           tf.range_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h25 (Dense)               (None, 9)            36          tf.dynamic_partition_16[0][1]    \n",
      "                                                                 tf.dynamic_partition_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma5 (Dense)         (None, 1)            4           tf.concat_11[0][0]               \n",
      "                                                                 tf.concat_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_20 (TFOpLa [(None,), (None,)]   0           tf.range_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h26 (Dense)               (None, 9)            36          tf.dynamic_partition_19[0][1]    \n",
      "                                                                 tf.dynamic_partition_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma6 (Dense)         (None, 1)            4           tf.concat_13[0][0]               \n",
      "                                                                 tf.concat_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_23 (TFOpLa [(None,), (None,)]   0           tf.range_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h27 (Dense)               (None, 9)            36          tf.dynamic_partition_22[0][1]    \n",
      "                                                                 tf.dynamic_partition_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma7 (Dense)         (None, 1)            4           tf.concat_15[0][0]               \n",
      "                                                                 tf.concat_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_partition_26 (TFOpLa [(None,), (None,)]   0           tf.range_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_h28 (Dense)               (None, 9)            36          tf.dynamic_partition_25[0][1]    \n",
      "                                                                 tf.dynamic_partition_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma8 (Dense)         (None, 1)            4           tf.concat_17[0][0]               \n",
      "                                                                 tf.concat_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.zeros_1 (TFOpLambda)         (None, 1)            0           tf.__operators__.getitem_30[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_18 (TFOpLambd (None, 1)            0           tf.dynamic_partition_29[0][0]    \n",
      "                                                                 tf.dynamic_partition_29[0][1]    \n",
      "                                                                 layer_h29[1][0]                  \n",
      "                                                                 layer_h29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_mean_dec_z (Dense)      (None, 2)            10          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.clip_by_value_2 (TFOpLambda) (None, 2)            0           tf.zeros[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch (TFOpLambda)  (None, 9)            0           tf.dynamic_partition_2[0][0]     \n",
      "                                                                 tf.dynamic_partition_2[0][1]     \n",
      "                                                                 layer_h20[1][0]                  \n",
      "                                                                 layer_h20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_1 (TFOpLambda (None, 1)            0           tf.dynamic_partition_2[0][0]     \n",
      "                                                                 tf.dynamic_partition_2[0][1]     \n",
      "                                                                 layer_h2_sigma0[1][0]            \n",
      "                                                                 layer_h2_sigma0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_2 (TFOpLambda (None, 9)            0           tf.dynamic_partition_5[0][0]     \n",
      "                                                                 tf.dynamic_partition_5[0][1]     \n",
      "                                                                 layer_h21[1][0]                  \n",
      "                                                                 layer_h21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_3 (TFOpLambda (None, 1)            0           tf.dynamic_partition_5[0][0]     \n",
      "                                                                 tf.dynamic_partition_5[0][1]     \n",
      "                                                                 layer_h2_sigma1[1][0]            \n",
      "                                                                 layer_h2_sigma1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_4 (TFOpLambda (None, 9)            0           tf.dynamic_partition_8[0][0]     \n",
      "                                                                 tf.dynamic_partition_8[0][1]     \n",
      "                                                                 layer_h22[1][0]                  \n",
      "                                                                 layer_h22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_5 (TFOpLambda (None, 1)            0           tf.dynamic_partition_8[0][0]     \n",
      "                                                                 tf.dynamic_partition_8[0][1]     \n",
      "                                                                 layer_h2_sigma2[1][0]            \n",
      "                                                                 layer_h2_sigma2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_6 (TFOpLambda (None, 9)            0           tf.dynamic_partition_11[0][0]    \n",
      "                                                                 tf.dynamic_partition_11[0][1]    \n",
      "                                                                 layer_h23[1][0]                  \n",
      "                                                                 layer_h23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_7 (TFOpLambda (None, 1)            0           tf.dynamic_partition_11[0][0]    \n",
      "                                                                 tf.dynamic_partition_11[0][1]    \n",
      "                                                                 layer_h2_sigma3[1][0]            \n",
      "                                                                 layer_h2_sigma3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_8 (TFOpLambda (None, 9)            0           tf.dynamic_partition_14[0][0]    \n",
      "                                                                 tf.dynamic_partition_14[0][1]    \n",
      "                                                                 layer_h24[1][0]                  \n",
      "                                                                 layer_h24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_9 (TFOpLambda (None, 1)            0           tf.dynamic_partition_14[0][0]    \n",
      "                                                                 tf.dynamic_partition_14[0][1]    \n",
      "                                                                 layer_h2_sigma4[1][0]            \n",
      "                                                                 layer_h2_sigma4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_10 (TFOpLambd (None, 9)            0           tf.dynamic_partition_17[0][0]    \n",
      "                                                                 tf.dynamic_partition_17[0][1]    \n",
      "                                                                 layer_h25[1][0]                  \n",
      "                                                                 layer_h25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_11 (TFOpLambd (None, 1)            0           tf.dynamic_partition_17[0][0]    \n",
      "                                                                 tf.dynamic_partition_17[0][1]    \n",
      "                                                                 layer_h2_sigma5[1][0]            \n",
      "                                                                 layer_h2_sigma5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_12 (TFOpLambd (None, 9)            0           tf.dynamic_partition_20[0][0]    \n",
      "                                                                 tf.dynamic_partition_20[0][1]    \n",
      "                                                                 layer_h26[1][0]                  \n",
      "                                                                 layer_h26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_13 (TFOpLambd (None, 1)            0           tf.dynamic_partition_20[0][0]    \n",
      "                                                                 tf.dynamic_partition_20[0][1]    \n",
      "                                                                 layer_h2_sigma6[1][0]            \n",
      "                                                                 layer_h2_sigma6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_14 (TFOpLambd (None, 9)            0           tf.dynamic_partition_23[0][0]    \n",
      "                                                                 tf.dynamic_partition_23[0][1]    \n",
      "                                                                 layer_h27[1][0]                  \n",
      "                                                                 layer_h27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_15 (TFOpLambd (None, 1)            0           tf.dynamic_partition_23[0][0]    \n",
      "                                                                 tf.dynamic_partition_23[0][1]    \n",
      "                                                                 layer_h2_sigma7[1][0]            \n",
      "                                                                 layer_h2_sigma7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_16 (TFOpLambd (None, 9)            0           tf.dynamic_partition_26[0][0]    \n",
      "                                                                 tf.dynamic_partition_26[0][1]    \n",
      "                                                                 layer_h28[1][0]                  \n",
      "                                                                 layer_h28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.dynamic_stitch_17 (TFOpLambd (None, 1)            0           tf.dynamic_partition_26[0][0]    \n",
      "                                                                 tf.dynamic_partition_26[0][1]    \n",
      "                                                                 layer_h2_sigma8[1][0]            \n",
      "                                                                 layer_h2_sigma8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_21 (TFOpLambda)       (None, 2)            0           tf.zeros_1[0][0]                 \n",
      "                                                                 tf.dynamic_stitch_18[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 386\n",
      "Trainable params: 19\n",
      "Non-trainable params: 367\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the decoder \n",
    "\n",
    "decoder_inputs_s = tf.keras.Input(shape=(s_dim, ))\n",
    "decoder_inputs_z = tf.keras.Input(shape=(z_dim, ))\n",
    "\n",
    "# params of p(z|s): p_params\n",
    "mean_pz = tf.keras.layers.Dense(units=z_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'mean_dec_z')(decoder_inputs_s)\n",
    "log_var_pz = tf.zeros([tf.shape(decoder_inputs_z)[0], z_dim])\n",
    "log_var_pz = tf.clip_by_value(log_var_pz, -15.0, 15.0)\n",
    "\n",
    "# Create deterministic layer y\n",
    "samples_y = tf.keras.layers.Dense(units=y_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_h1_')(decoder_inputs_z)\n",
    "\n",
    "grouped_samples_y = []\n",
    "partition_vector_cumsum = np.insert(np.cumsum(y_dim_partition), 0, 0)\n",
    "for i in range(len(types_dict)):\n",
    "    grouped_samples_y.append(samples_y[:, partition_vector_cumsum[i]:partition_vector_cumsum[i+1]])\n",
    "\n",
    "theta = theta_estimation_from_ys(grouped_samples_y, decoder_inputs_s, types_dict, miss_mask)\n",
    "\n",
    "decoder = tf.keras.Model(inputs=[decoder_inputs_s, decoder_inputs_z], outputs=[mean_pz, log_var_pz, theta], name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "in user code:\n\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"Maximum_8:0\", shape=(None, 2), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3e786c1136f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmse_loss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: in user code:\n\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"Maximum_8:0\", shape=(None, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "decoder.compile(optimizer=optimizer, loss=mse_loss_fn)\n",
    "decoder.fit(normalized_data[:, 0:4], [normalized_data[:, 0:4], normalized_data[:, 5:6]], batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_as_feature_list(data, types_dict):\n",
    "    \n",
    "    data_list = []\n",
    "    initial_index = 0\n",
    "    for d in types_dict:\n",
    "        dim = int(d['dim'])\n",
    "        data_list.append(data[:,initial_index:initial_index+dim])\n",
    "        initial_index += dim\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_evaluation(normalized_data_as_list, types_dict, miss_mask, theta, tau2, normalization_params):\n",
    "    log_p_x = []\n",
    "    log_p_x_missing = []\n",
    "    samples_x = []\n",
    "    params_x = []\n",
    "\n",
    "    #Independet yd -> Compute log(p(xd|yd))\n",
    "    for i,d in enumerate(normalized_data_as_list):\n",
    "        # Select the likelihood for the types of variables\n",
    "        loglik_function = getattr(loglik_models_missing_normalize, 'loglik_' + types_dict[i]['type'])\n",
    "        out = loglik_function([d,miss_mask[:,i]], types_dict[i], theta[i], normalization_params[i], tau2,\n",
    "                                      kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_mean_dec_x' + str(i))\n",
    "        log_p_x.append(out['log_p_x'])\n",
    "    return log_p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE as a Model with a custom 'train_step'\n",
    "\n",
    "tau2 = .001\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "        \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape: \n",
    "            log_pi_aux, s, mean_qz, log_var_qz, z = encoder(data)\n",
    "            mean_pz, log_var_pz, theta = decoder([s, z])\n",
    "            reconstruction = mean_pz\n",
    "\n",
    "            # Computing the loss\n",
    "            # KL(q(s|x)||p(s))\n",
    "            log_pi = log_pi_aux\n",
    "            pi_param = tf.nn.softmax(log_pi)\n",
    "            KL_s = -tf.nn.softmax_cross_entropy_with_logits(labels=pi_param, logits=log_pi) + tf.math.log(float(s_dim))\n",
    "            \n",
    "            # KL(q(z|s,x)||p(z|s))\n",
    "            KL_z = -0.5*z_dim + 0.5*tf.reduce_sum(tf.exp(log_var_qz-log_var_pz) + tf.square(mean_pz-mean_qz)/tf.exp(log_var_pz) - log_var_qz + log_var_pz, 1)\n",
    "            \n",
    "            #Eq[log_p(x|y)]\n",
    "            normalized_data_as_list = data_as_feature_list(normalized_data, types_dict)\n",
    "            \n",
    "            log_p_x = loglik_evaluation(normalized_data_as_list, types_dict, miss_mask, theta, tau2, normalization_parameters)\n",
    "\n",
    "            loss_reconstruction = tf.reduce_sum(log_p_x, 0)\n",
    "            \n",
    "            # Complete ELBO \n",
    "            ELBO = tf.reduce_mean(loss_reconstruction - KL_z - KL_s, 0)\n",
    "            \n",
    "        grads = tape.gradient(ELBO, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            'loss': ELBO,\n",
    "            'reconstruction_loss': loss_reconstruction, \n",
    "            'kl_loss': KL_s + KL_z,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE \n",
    "\n",
    "# (x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "# mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "# mnist_digits = np.expand_dims(mnist_digits, -1).astype('float32')/255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = 'logs/vae/'+datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([699, 92])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input to reshape is a tensor with 100 values, but the requested shape has 699\n\t [[node softmax_cross_entropy_with_logits/Reshape_2 (defined at <ipython-input-28-8b15a227366d>:22) ]] [Op:__inference_train_function_15551]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-0f06e377ac60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 100 values, but the requested shape has 699\n\t [[node softmax_cross_entropy_with_logits/Reshape_2 (defined at <ipython-input-28-8b15a227366d>:22) ]] [Op:__inference_train_function_15551]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "vae.fit(normalized_data, normalized_data, epochs=5, batch_size=100, callbacks=tensorboard_callback) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function for testing purposes before actually starting the training \n",
    "# Inputs: Raw_data, Normalized_data, miss_list, types_list, batch_size, z_dim, y_dim_output, y_dim_partition, s_dim, tau, tau2, normalization_params\n",
    "\n",
    "samples_test = dict.fromkeys(['s', 'z', 'y', 'x'])\n",
    "test_params = dict()\n",
    "X = tf.concat(X_list, 1)\n",
    "\n",
    "# Create the proposal of q(s|x^o)\n",
    "_, params = s_proposal_multinomial_encoder(X, s_dim, tau)\n",
    "samples_test['s'] = tf.one_hot(tf.argmax(params, 1), depth=s_dim)\n",
    "\n",
    "# Create the proposal of q(z|s,x^o)\n",
    "_, params = z_proposal_GMM_encoder(X, samples_test['s'], z_dim)\n",
    "samples_test['z'] = params[0]\n",
    "\n",
    "# Create deterministic layer y\n",
    "samples_test['y'] = tf.keras.layers.Dense(units=y_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_h1_', reuse=True)\n",
    "grouped_samples_y = y_partition(samples_test['y'], types_list, y_dim_partition)\n",
    "\n",
    "# Compute the parameters h_y\n",
    "theta = theta_estimation_from_ys(grouped_samples_y, samples_test['s'], types_list, miss_list, batch_size, reuse=True)\n",
    "\n",
    "# Compute loglik and output of the VAE\n",
    "log_p_x, log_p_x_missing, samples_test['x'], test_params['x'] = loglik_evaluation(batch_data_list, types_list, miss_list, theta, tau2, normalization_params, reuse=True)\n",
    "\n",
    "# Returns samples_test, test_params, log_p_x, log_p_x_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/vae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
