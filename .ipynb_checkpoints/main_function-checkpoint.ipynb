{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import parser_arguments\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import loglik_models_missing_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser_arguments.getArgs(sys.argv[1:])\n",
    "args = parser_arguments.getArgs_jupyter_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./Saved_Networks/'+args.save_file):\n",
    "    os.makedirs('./Saved_Networks/'+args.save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_file_name = './Saved_Networks/' + args.save_file + '/' + args.save_file + '.ckpt'\n",
    "log_file_name = './Saved_Networks' + args.save_file + '/log_file_' + args.save_file + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 200, 'epochs': 5, 'perp': 10, 'train': 1, 'display': 1, 'save': 1000, 'restore': 0, 'plot': 1, 'dim_latent_s': 4, 'dim_latent_z': 2, 'dim_latent_y': 3, 'dim_latent_y_partition': [], 'miss_perentage_train': 0.0, 'miss_percentage_test': 0.0, 'model_name': 'model_new', 'save_file': 'breast_data_zdim5_ydim10_4images_', 'data_file': './Breast/data.csv', 'types_file': './Breast/data_types.csv', 'miss_file': './Breast/Missing40_4.csv', 'true_miss_file': ''}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read functions.read_data \n",
    "# Inputs: data_file, types_file, miss_file, true_miss_file\n",
    "\n",
    "nan_definition = [-9999., 'nan']\n",
    "# Read types of data from types_file\n",
    "data_types = pd.read_csv(args.types_file)\n",
    "types_dict = data_types.to_dict('records')\n",
    "\n",
    "\n",
    "# Read data from the input file, compute the true missing mask and replace the true missing values with placeholder value\n",
    "column_names = [item['type']+'_'+str(i) for i, item in enumerate(types_dict)]\n",
    "\n",
    "data_df = pd.read_csv(args.data_file, header=None, na_values=nan_definition, names=column_names, dtype=np.float64)\n",
    "filler_value = dict()\n",
    "for col in column_names:\n",
    "    if 'cat' in col or 'ordinal' in col: \n",
    "        filler_value[col] = np.unique(data_df[col])[0]\n",
    "    else: \n",
    "        filler_value[col] = 0.0\n",
    "        \n",
    "data_df_filled = np.array(data_df.fillna(value=filler_value))\n",
    "\n",
    "true_miss_mask = pd.notna(data_df).astype(int)\n",
    "\n",
    "# Construct the data matrices\n",
    "data_complete = []\n",
    "for i in range(np.shape(data_df_filled)[1]):\n",
    "    if types_dict[i]['type']=='cat':\n",
    "        cat_data = [int(x) for x in data_df_filled[:, i]]\n",
    "        _, indexes = np.unique(cat_data, return_inverse=True)\n",
    "        # Transform categories to a vector of 0:n_categories\n",
    "        new_categories = np.arange(int(types_dict[i]['dim']))\n",
    "        cat_data = new_categories[indexes]\n",
    "        # Create one-hot encoding for the categories \n",
    "        temp = np.zeros([np.shape(data_df_filled)[0], len(new_categories)])\n",
    "        temp[np.arange(np.shape(data_df_filled)[0]), cat_data] = 1\n",
    "        data_complete.append(temp)\n",
    "    elif types_dict[i]['type']=='ordinal':\n",
    "        cat_data = [int(x) for x in data_df_filled[:, i]]\n",
    "        _, indexes = np.unique(cat_data, return_inverse=True)\n",
    "        # Transform categories to a vector of 0:n_categories \n",
    "        new_categories = np.arange(int(types_dict[i]['dim']))\n",
    "        cat_data = new_categories[indexes]\n",
    "        # Create thermometer encoding for the categories \n",
    "        temp = np.zeros([np.shape(data_df_filled)[0], 1+len(new_categories)])\n",
    "        temp[:, 0] = 1\n",
    "        temp[np.arange(np.shape(data_df_filled)[0]), 1+cat_data] = -1\n",
    "        temp = np.cumsum(temp, 1)\n",
    "        data_complete.append(temp[:, :-1])\n",
    "    elif types_dict[i]['type'] == 'count':\n",
    "        if np.min(data_df_filled[:, i]) == 0:\n",
    "            temp = data_df_filled[:, i] + 1\n",
    "            data_complete.append(np.transpose([temp]))\n",
    "        else:\n",
    "            data_complete.append(np.transpose([data_df_filled[:, i]]))\n",
    "    else:\n",
    "        data_complete.append(np.transpose([data_df_filled[:, i]]))\n",
    "data = np.concatenate(data_complete, 1)\n",
    "\n",
    "# Read missing mask from .csv (contains positions of missing values)\n",
    "n_samples = np.shape(data)[0]\n",
    "n_variables = len(types_dict)\n",
    "miss_mask = np.ones([np.shape(data)[0], n_variables])\n",
    "# if there is no mask, assume all data is observed \n",
    "missing_positions = np.array(pd.read_csv(args.miss_file, header=None))       \n",
    "miss_mask[missing_positions[:,0]-1, missing_positions[:,1]-1] = 0\n",
    "\n",
    "# This cell returns: data, types_dict, miss_mask, true_miss_mask, n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an integer number of batches \n",
    "if args.batch_size > n_samples:\n",
    "    args.batch_size = n_samples\n",
    "# Get an integer number of batches \n",
    "n_batches = int(np.floor(np.shape(data)[0]/args.batch_size))\n",
    "# Compute the real miss_mask\n",
    "real_miss_mask = np.array(np.multiply(miss_mask, true_miss_mask)).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_index = 0\n",
    "normalized_data = []\n",
    "normalization_parameters = []\n",
    "for i in range(len(types_dict)):\n",
    "    missing_data, observed_data = tf.dynamic_partition(data[:,ftr_index:ftr_index+types_dict[i]['dim']], real_miss_mask[:,i], num_partitions=2)\n",
    "    condition_indices = tf.dynamic_partition(tf.range(tf.shape(data)[0]), real_miss_mask[:, i], num_partitions=2)\n",
    "\n",
    "    if types_dict[i]['type'] == 'real':\n",
    "        data_mean, data_var = tf.nn.moments(observed_data, 0)\n",
    "        data_var = tf.clip_by_value(data_var, 1e-6, 1e20) # Avoid zero values\n",
    "        norm_X = tf.nn.batch_normalization(observed_data, data_mean, data_var, offset=0.0, scale=1.0, variance_epsilon=1e-6)\n",
    "\n",
    "        normalized_data.append(tf.dynamic_stitch(condition_indices, [missing_data, norm_X]))\n",
    "        normalization_parameters.append([data_mean, data_var])\n",
    "\n",
    "    elif types_dict[i]['type'] == 'pos':\n",
    "        # we transform the log of the data to a gaussian with mean 0 and std 1\n",
    "        observed_data_log = tf.log(1.0+observed_data)\n",
    "        data_mean_log, data_var_log = tf.nn.moments(observed_data_log, 0)\n",
    "        data_var_log = tf.clip_by_value(data_var_log, 1e-6, 1e20) \n",
    "        norm_X = tf.nn.batch_normalization(observed_data_log, data_mean_log, data_var_log, offset=0.0, scale=1.0, variance_epsilon=1e-6)\n",
    "\n",
    "        normalized_data.append(tf.dynamic_stitch(condition_indices, [missing_data, norm_X]))\n",
    "        normalization_parameters.append([data_mean_log, data_var_log])\n",
    "\n",
    "    elif types_dict[i]['type'] == 'count':\n",
    "        aux_X = tf.math.log(observed_data)\n",
    "\n",
    "        normalized_data.append(tf.dynamic_stitch(condition_indices, [missing_data, aux_X]))\n",
    "        normalization_parameters.append([0.0, 1.0])\n",
    "\n",
    "    else:\n",
    "        normalized_data.append(data[:, ftr_index:ftr_index+types_dict[i]['dim']])\n",
    "        normalization_parameters.append([0.0, 1.0])\n",
    "    ftr_index = ftr_index + types_dict[i]['dim']\n",
    "\n",
    "normalized_data = tf.concat(normalized_data, 1)\n",
    "\n",
    "# This block returns normalized_data, normalization_parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimensionality of Y \n",
    "y_dim = args.dim_latent_y\n",
    "y_dim_partition = args.dim_latent_y_partition\n",
    "if y_dim_partition:\n",
    "    y_dim_output = np.sum(y_dim_partition)\n",
    "else:\n",
    "    y_dim_partition = y_dim*np.ones(len(types_dict), dtype=int)\n",
    "    y_dim_output = np.sum(y_dim_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_miss_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_dataset = tf.data.Dataset.from_tensor_slices((normalized_data, miss_mask, real_miss_mask)).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY AREA\n",
    "# *****************************************************************************************************************\n",
    "# Perform batch normalization of the data \n",
    "\n",
    "# normalizer = preprocessing.Normalization(input_shape=(data.shape[1],))\n",
    "# normalizer.adapt(data) # normalizer is now a tf.keras layer and can be used as the first layer of your NN model!!\n",
    "# mean = normalizer.mean.numpy()\n",
    "# variance = normalizer.variance.numpy()\n",
    "# *****************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling_s(tf.keras.layers.Layer):\n",
    "    \"\"\" Uses Gumbel Softmax trick to sample s, the mixture component random variable that generates the latent variable z from a GMM. The Gumbel Softmax formulation \n",
    "    helps to implement the reparameterization trick for the discrete random variable 's' specified by activations, log_pi_aux. \n",
    "    \"\"\"\n",
    "    def __init__(self, tau):\n",
    "        super(Sampling_s, self).__init__()\n",
    "        self.tau = tau\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_activations = inputs\n",
    "        no_of_samples = tf.shape(input_activations)[0]\n",
    "        s_dim = tf.shape(input_activations)[1]\n",
    "        U = -tf.math.log(-tf.math.log(tf.random.uniform([no_of_samples, s_dim])))\n",
    "        samples_s = tf.nn.softmax((input_activations+U)/self.tau)\n",
    "        return samples_s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling_z_given_s(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, given the samples of s. The random variable z is assumed to follow a GMM.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5*z_log_var)*epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 92)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_enc_s (Dense)           (None, 4)            372         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax_2 (TensorFl [(None, 4)]          0           layer_1_enc_s[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Minimum_6 (TensorFl [(None, 4)]          0           tf_op_layer_Softmax_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Maximum_6 (TensorFl [(None, 4)]          0           tf_op_layer_Minimum_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_2 (TensorFlowOp [(None, 4)]          0           tf_op_layer_Maximum_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sampling_s_2 (Sampling_s)       (None, 4)            0           tf_op_layer_Log_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_23 (TensorFl [(None, 96)]         0           input_7[0][0]                    \n",
      "                                                                 sampling_s_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_logvar_enc_z (Dense)    (None, 2)            194         tf_op_layer_concat_23[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Minimum_7 (TensorFl [(None, 2)]          0           layer_1_logvar_enc_z[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_mean_enc_z (Dense)      (None, 2)            194         tf_op_layer_concat_23[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Maximum_7 (TensorFl [(None, 2)]          0           tf_op_layer_Minimum_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sampling_z_given_s_2 (Sampling_ (None, 2)            0           layer_1_mean_enc_z[0][0]         \n",
      "                                                                 tf_op_layer_Maximum_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 760\n",
      "Trainable params: 760\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the Encoder \n",
    "\n",
    "tau = 1.00\n",
    "no_of_features = normalized_data.shape[1]\n",
    "s_dim = args.dim_latent_s\n",
    "z_dim = args.dim_latent_z\n",
    "\n",
    "sample_s = Sampling_s(tau) # Create an object\n",
    "\n",
    "encoder_inputs = tf.keras.Input(shape=(no_of_features, ))\n",
    "log_pi = tf.keras.layers.Dense(units=s_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'enc_s')\n",
    "x = log_pi(encoder_inputs)\n",
    "log_pi_aux = tf.math.log(tf.clip_by_value(tf.nn.softmax(x), 1e-6, 1))\n",
    "\n",
    "s = sample_s(log_pi_aux)\n",
    "\n",
    "input_data_and_s = tf.concat([encoder_inputs, s], 1)\n",
    "mean_qz = tf.keras.layers.Dense(units=z_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'mean_enc_z')(input_data_and_s)\n",
    "log_var_qz = tf.keras.layers.Dense(units=z_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'logvar_enc_z')(input_data_and_s)\n",
    "\n",
    "# Avoid numerical problems\n",
    "log_var_qz = tf.clip_by_value(log_var_qz, -15.0, 15.0)\n",
    "    \n",
    "z = Sampling_z_given_s()([mean_qz, log_var_qz])\n",
    "\n",
    "encoder = tf.keras.Model(encoder_inputs, [log_pi_aux, s, mean_qz, log_var_qz, z], name='encoder')  # check for reuse functionality of some layers here ????????\n",
    "# encoder = tf.keras.Model(encoder_inputs, log_pi_aux, name='encoder')  # check for reuse functionality of some layers here ????????\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8675\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8349\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8257\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8201\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8159\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8127\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8102\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 4.8082\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8066\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e81031b148>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "encoder.compile(optimizer=optimizer, loss=mse_loss_fn)\n",
    "encoder.fit(normalized_data, normalized_data[:, 0:4], batch_size=32, epochs=10)\n",
    "# Iterate over epochs.\n",
    "# for epoch in range(epochs):\n",
    "#     print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "#     # Iterate over the batches of the dataset.\n",
    "#     for step, x_batch_train in enumerate(train_dataset):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             reconstructed = encoder(x_batch_train)\n",
    "#             # Compute reconstruction loss\n",
    "#             loss = mse_loss_fn(x_batch_train[:, 0:4], reconstructed[0])\n",
    "#             loss += sum(encoder.losses)  # Add KLD regularization loss\n",
    "\n",
    "#         grads = tape.gradient(loss, encoder.trainable_weights)\n",
    "#         optimizer.apply_gradients(zip(grads, encoder.trainable_weights))\n",
    "\n",
    "#         loss_metric(loss)\n",
    "\n",
    "#         if step % 100 == 0:\n",
    "#             print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_partition(samples_y, types_list, y_dim_partition):\n",
    "    grouped_samples_y = []\n",
    "    partition_vector_cumsum = np.insert(np.cumsum(y_dim_partition), 0, 0)\n",
    "    for i in range(len(types_list)):\n",
    "        grouped_samples_y.append(samples_y[:, partition_vector_cumsum[i]:partition_vector_cumsum[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observed_data_layer(observed_data, missing_data, condition_indices, output_dim, name, bias):\n",
    "    #Train a layer with the observed data and reuse it for the missing data\n",
    "    output_layer = tf.keras.layers.Dense(units=output_dim, activation=None,\n",
    "                         kernel_initializer=tf.random_normal_initializer(stddev=0.05),name=name,use_bias=bias)\n",
    "    output_layer.trainable=True\n",
    "    obs_output = output_layer(observed_data)\n",
    "    \n",
    "    output_layer.trainable = False\n",
    "    miss_output = output_layer(missing_data) \n",
    "    #Join back the data\n",
    "    output = tf.dynamic_stitch(condition_indices, [miss_output,obs_output])\n",
    "    return output\n",
    "\n",
    "\n",
    "def theta_real_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i, reuse):\n",
    "    #Mean layer    \n",
    "    h2_mean = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=types_list[i]['dim'], name='layer_h2' + str(i), reuse=reuse, bias=False)\n",
    "    #Sigma Layer    \n",
    "    h2_sigma = observed_data_layer(observed_s, missing_s, condition_indices, output_dim=types_list[i]['dim'], name='layer_h2_sigma' + str(i), reuse=reuse, bias=False)\n",
    "    return [h2_mean, h2_sigma]\n",
    "\n",
    "def theta_pos_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i, reuse):\n",
    "    \n",
    "    #Mean layer\n",
    "    h2_mean = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=types_list[i]['dim'], name='layer_h2' + str(i), reuse=reuse, bias=False)\n",
    "    \n",
    "    #Sigma Layer\n",
    "    h2_sigma = observed_data_layer(observed_s, missing_s, condition_indices, output_dim=types_list[i]['dim'], name='layer_h2_sigma' + str(i), reuse=reuse, bias=False)\n",
    "    \n",
    "    return [h2_mean, h2_sigma]\n",
    "\n",
    "def theta_count_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i, reuse):\n",
    "    \n",
    "    #Lambda Layer    \n",
    "    h2_lambda = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=types_list[i]['dim'], name='layer_h2' + str(i), reuse=reuse, bias=False)\n",
    "    \n",
    "    return h2_lambda\n",
    "\n",
    "def theta_cat_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i):\n",
    "    \n",
    "    #Log pi layer, with zeros in the first value to avoid the identificability problem   \n",
    "    h2_log_pi_partial = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=int(types_list[i]['dim'])-1, name='layer_h2' + str(i), bias=False)\n",
    "    h2_log_pi = tf.concat([tf.zeros([nObs,1]), h2_log_pi_partial],1)\n",
    "    return h2_log_pi\n",
    "\n",
    "def theta_ordinal_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i):\n",
    "    \n",
    "    #Theta layer, Dimension of ordinal - 1\n",
    "#     print(observed_y.shape)\n",
    "    h2_theta = observed_data_layer(observed_s, missing_s, condition_indices, output_dim=int(types_list[i]['dim'])-1, name='layer_h2' + str(i), bias=False)\n",
    "    \n",
    "    #Mean layer, a single value\n",
    "    h2_mean = observed_data_layer(tf.concat([observed_y,observed_s],1), tf.concat([missing_y,missing_s],1), condition_indices, output_dim=1, name='layer_h2_sigma' + str(i), bias=False)\n",
    "    \n",
    "    return [h2_theta, h2_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_estimation_from_ys(samples_y, samples_s, types_list, miss_list):\n",
    "    theta = []\n",
    "    # Independent yd -> Compute p(xd|yd)\n",
    "    for i, d in enumerate(samples_y):\n",
    "        # Partition the data in missing data(0) and observed data(1)\n",
    "        missing_y, observed_y = tf.dynamic_partition(d, miss_list[:, i], num_partitions=2)\n",
    "        missing_s, observed_s = tf.dynamic_partition(samples_s, miss_list[:, i], num_partitions=2)\n",
    "        condition_indices = tf.dynamic_partition(tf.range(tf.shape(d)[0]), miss_list[:, i], num_partitions=2)\n",
    "        nObs = tf.shape(observed_y)[0]\n",
    "        \n",
    "        # Different layer models for each type of variable\n",
    "        if types_list[i]['type']=='real':\n",
    "            params = theta_real_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "        \n",
    "        elif types_list[i]['type']=='pos':\n",
    "            params = theta_pos_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "            \n",
    "        elif types_list[i]['type']=='count':\n",
    "            params = theta_count_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "        \n",
    "        elif types_list[i]['type']=='cat':\n",
    "            params = theta_cat_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "            \n",
    "        elif types_list[i]['type']=='ordinal':\n",
    "            params = theta_ordinal_s(observed_y, missing_y, observed_s, missing_s, condition_indices, types_list, nObs, i)\n",
    "        theta.append(params)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_h1_ (Dense)               (None, 3)            9           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_52 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_22 (TensorFlo [(2,)]               0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_43 (T [(None, 3)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_44 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_45 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_46 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_47 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_48 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_49 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_50 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_51 (T [(None, 0)]          0           layer_h1_[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_57 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_52[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_41 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_52[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_42 (T [()]                 0           tf_op_layer_Shape_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_23 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_43[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_25 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_44[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_27 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_45[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_29 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_46[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_31 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_47[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_33 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_48[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_35 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_49[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_37 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_50[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_39 (TensorFlo [(2,)]               0           tf_op_layer_strided_slice_51[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_42 (TensorFlo [(2,)]               0           tf_op_layer_DynamicPartition_57[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_71 (T [()]                 0           tf_op_layer_Shape_41[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_58 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Pack_3 (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice_42[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_53 (T [()]                 0           tf_op_layer_Shape_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_31 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_30 [(None, 3), (None, 3 0           tf_op_layer_strided_slice_43[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_55 (T [()]                 0           tf_op_layer_Shape_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_34 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_33 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_44[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_57 (T [()]                 0           tf_op_layer_Shape_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_37 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_36 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_45[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_59 (T [()]                 0           tf_op_layer_Shape_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_40 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_39 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_46[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_61 (T [()]                 0           tf_op_layer_Shape_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_43 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_42 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_47[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_63 (T [()]                 0           tf_op_layer_Shape_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_46 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_45 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_48[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_65 (T [()]                 0           tf_op_layer_Shape_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_49 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_48 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_49[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_67 (T [()]                 0           tf_op_layer_Shape_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_52 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_51 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_50[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_69 (T [()]                 0           tf_op_layer_Shape_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_55 [(None, 4), (None, 4 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_54 [(None, 0), (None, 0 0           tf_op_layer_strided_slice_51[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_72 (T [()]                 0           tf_op_layer_Shape_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_19 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_71[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_43 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_57[0\n",
      "                                                                 tf_op_layer_DynamicPartition_58[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_42 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_57[0\n",
      "                                                                 tf_op_layer_DynamicPartition_58[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Fill_3 (TensorFlowO [(None, 2)]          0           tf_op_layer_Pack_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_10 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_53[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_25 (TensorFl [(None, 7)]          0           tf_op_layer_DynamicPartition_30[0\n",
      "                                                                 tf_op_layer_DynamicPartition_31[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_24 (TensorFl [(None, 7)]          0           tf_op_layer_DynamicPartition_30[0\n",
      "                                                                 tf_op_layer_DynamicPartition_31[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_11 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_55[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_27 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_33[0\n",
      "                                                                 tf_op_layer_DynamicPartition_34[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_26 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_33[0\n",
      "                                                                 tf_op_layer_DynamicPartition_34[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_12 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_57[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_29 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_36[0\n",
      "                                                                 tf_op_layer_DynamicPartition_37[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_28 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_36[0\n",
      "                                                                 tf_op_layer_DynamicPartition_37[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_13 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_59[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_31 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_39[0\n",
      "                                                                 tf_op_layer_DynamicPartition_40[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_30 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_39[0\n",
      "                                                                 tf_op_layer_DynamicPartition_40[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_14 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_61[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_33 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_42[0\n",
      "                                                                 tf_op_layer_DynamicPartition_43[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_32 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_42[0\n",
      "                                                                 tf_op_layer_DynamicPartition_43[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_15 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_63[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_35 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_45[0\n",
      "                                                                 tf_op_layer_DynamicPartition_46[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_34 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_45[0\n",
      "                                                                 tf_op_layer_DynamicPartition_46[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_16 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_65[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_37 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_48[0\n",
      "                                                                 tf_op_layer_DynamicPartition_49[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_36 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_48[0\n",
      "                                                                 tf_op_layer_DynamicPartition_49[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_17 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_67[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_39 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_51[0\n",
      "                                                                 tf_op_layer_DynamicPartition_52[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_38 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_51[0\n",
      "                                                                 tf_op_layer_DynamicPartition_52[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_18 (TensorFlo [(None,)]            0           tf_op_layer_strided_slice_69[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_41 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_54[0\n",
      "                                                                 tf_op_layer_DynamicPartition_55[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_40 (TensorFl [(None, 4)]          0           tf_op_layer_DynamicPartition_54[0\n",
      "                                                                 tf_op_layer_DynamicPartition_55[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Pack_4 (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice_72[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_59 [(None,), (None,)]   0           tf_op_layer_Range_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h29 (Dense)               (None, 1)            4           tf_op_layer_concat_42[0][0]      \n",
      "                                                                 tf_op_layer_concat_43[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Minimum_8 (TensorFl [(None, 2)]          0           tf_op_layer_Fill_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_32 [(None,), (None,)]   0           tf_op_layer_Range_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h20 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_31[0\n",
      "                                                                 tf_op_layer_DynamicPartition_31[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma0 (Dense)         (None, 1)            7           tf_op_layer_concat_24[0][0]      \n",
      "                                                                 tf_op_layer_concat_25[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_35 [(None,), (None,)]   0           tf_op_layer_Range_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h21 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_34[0\n",
      "                                                                 tf_op_layer_DynamicPartition_34[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma1 (Dense)         (None, 1)            4           tf_op_layer_concat_26[0][0]      \n",
      "                                                                 tf_op_layer_concat_27[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_38 [(None,), (None,)]   0           tf_op_layer_Range_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h22 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_37[0\n",
      "                                                                 tf_op_layer_DynamicPartition_37[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma2 (Dense)         (None, 1)            4           tf_op_layer_concat_28[0][0]      \n",
      "                                                                 tf_op_layer_concat_29[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_41 [(None,), (None,)]   0           tf_op_layer_Range_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h23 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_40[0\n",
      "                                                                 tf_op_layer_DynamicPartition_40[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma3 (Dense)         (None, 1)            4           tf_op_layer_concat_30[0][0]      \n",
      "                                                                 tf_op_layer_concat_31[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_44 [(None,), (None,)]   0           tf_op_layer_Range_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h24 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_43[0\n",
      "                                                                 tf_op_layer_DynamicPartition_43[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma4 (Dense)         (None, 1)            4           tf_op_layer_concat_32[0][0]      \n",
      "                                                                 tf_op_layer_concat_33[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_47 [(None,), (None,)]   0           tf_op_layer_Range_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h25 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_46[0\n",
      "                                                                 tf_op_layer_DynamicPartition_46[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma5 (Dense)         (None, 1)            4           tf_op_layer_concat_34[0][0]      \n",
      "                                                                 tf_op_layer_concat_35[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_50 [(None,), (None,)]   0           tf_op_layer_Range_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h26 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_49[0\n",
      "                                                                 tf_op_layer_DynamicPartition_49[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma6 (Dense)         (None, 1)            4           tf_op_layer_concat_36[0][0]      \n",
      "                                                                 tf_op_layer_concat_37[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_53 [(None,), (None,)]   0           tf_op_layer_Range_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h27 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_52[0\n",
      "                                                                 tf_op_layer_DynamicPartition_52[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma7 (Dense)         (None, 1)            4           tf_op_layer_concat_38[0][0]      \n",
      "                                                                 tf_op_layer_concat_39[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicPartition_56 [(None,), (None,)]   0           tf_op_layer_Range_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_h28 (Dense)               (None, 9)            36          tf_op_layer_DynamicPartition_55[0\n",
      "                                                                 tf_op_layer_DynamicPartition_55[0\n",
      "__________________________________________________________________________________________________\n",
      "layer_h2_sigma8 (Dense)         (None, 1)            4           tf_op_layer_concat_40[0][0]      \n",
      "                                                                 tf_op_layer_concat_41[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Fill_4 (TensorFlowO [(None, 1)]          0           tf_op_layer_Pack_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_37 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_59[0\n",
      "                                                                 tf_op_layer_DynamicPartition_59[0\n",
      "                                                                 layer_h29[1][0]                  \n",
      "                                                                 layer_h29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_mean_dec_z (Dense)      (None, 2)            10          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Maximum_8 (TensorFl [(None, 2)]          0           tf_op_layer_Minimum_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_19 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_32[0\n",
      "                                                                 tf_op_layer_DynamicPartition_32[0\n",
      "                                                                 layer_h20[1][0]                  \n",
      "                                                                 layer_h20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_20 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_32[0\n",
      "                                                                 tf_op_layer_DynamicPartition_32[0\n",
      "                                                                 layer_h2_sigma0[1][0]            \n",
      "                                                                 layer_h2_sigma0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_21 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_35[0\n",
      "                                                                 tf_op_layer_DynamicPartition_35[0\n",
      "                                                                 layer_h21[1][0]                  \n",
      "                                                                 layer_h21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_22 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_35[0\n",
      "                                                                 tf_op_layer_DynamicPartition_35[0\n",
      "                                                                 layer_h2_sigma1[1][0]            \n",
      "                                                                 layer_h2_sigma1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_23 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_38[0\n",
      "                                                                 tf_op_layer_DynamicPartition_38[0\n",
      "                                                                 layer_h22[1][0]                  \n",
      "                                                                 layer_h22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_24 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_38[0\n",
      "                                                                 tf_op_layer_DynamicPartition_38[0\n",
      "                                                                 layer_h2_sigma2[1][0]            \n",
      "                                                                 layer_h2_sigma2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_25 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_41[0\n",
      "                                                                 tf_op_layer_DynamicPartition_41[0\n",
      "                                                                 layer_h23[1][0]                  \n",
      "                                                                 layer_h23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_26 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_41[0\n",
      "                                                                 tf_op_layer_DynamicPartition_41[0\n",
      "                                                                 layer_h2_sigma3[1][0]            \n",
      "                                                                 layer_h2_sigma3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_27 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_44[0\n",
      "                                                                 tf_op_layer_DynamicPartition_44[0\n",
      "                                                                 layer_h24[1][0]                  \n",
      "                                                                 layer_h24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_28 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_44[0\n",
      "                                                                 tf_op_layer_DynamicPartition_44[0\n",
      "                                                                 layer_h2_sigma4[1][0]            \n",
      "                                                                 layer_h2_sigma4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_29 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_47[0\n",
      "                                                                 tf_op_layer_DynamicPartition_47[0\n",
      "                                                                 layer_h25[1][0]                  \n",
      "                                                                 layer_h25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_30 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_47[0\n",
      "                                                                 tf_op_layer_DynamicPartition_47[0\n",
      "                                                                 layer_h2_sigma5[1][0]            \n",
      "                                                                 layer_h2_sigma5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_31 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_50[0\n",
      "                                                                 tf_op_layer_DynamicPartition_50[0\n",
      "                                                                 layer_h26[1][0]                  \n",
      "                                                                 layer_h26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_32 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_50[0\n",
      "                                                                 tf_op_layer_DynamicPartition_50[0\n",
      "                                                                 layer_h2_sigma6[1][0]            \n",
      "                                                                 layer_h2_sigma6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_33 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_53[0\n",
      "                                                                 tf_op_layer_DynamicPartition_53[0\n",
      "                                                                 layer_h27[1][0]                  \n",
      "                                                                 layer_h27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_34 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_53[0\n",
      "                                                                 tf_op_layer_DynamicPartition_53[0\n",
      "                                                                 layer_h2_sigma7[1][0]            \n",
      "                                                                 layer_h2_sigma7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_35 (T [(None, 9)]          0           tf_op_layer_DynamicPartition_56[0\n",
      "                                                                 tf_op_layer_DynamicPartition_56[0\n",
      "                                                                 layer_h28[1][0]                  \n",
      "                                                                 layer_h28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DynamicStitch_36 (T [(None, 1)]          0           tf_op_layer_DynamicPartition_56[0\n",
      "                                                                 tf_op_layer_DynamicPartition_56[0\n",
      "                                                                 layer_h2_sigma8[1][0]            \n",
      "                                                                 layer_h2_sigma8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_44 (TensorFl [(None, 2)]          0           tf_op_layer_Fill_4[0][0]         \n",
      "                                                                 tf_op_layer_DynamicStitch_37[0][0\n",
      "==================================================================================================\n",
      "Total params: 386\n",
      "Trainable params: 19\n",
      "Non-trainable params: 367\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the decoder \n",
    "\n",
    "decoder_inputs_s = tf.keras.Input(shape=(s_dim, ))\n",
    "decoder_inputs_z = tf.keras.Input(shape=(z_dim, ))\n",
    "\n",
    "# params of p(z|s): p_params\n",
    "mean_pz = tf.keras.layers.Dense(units=z_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_'+'mean_dec_z')(decoder_inputs_s)\n",
    "log_var_pz = tf.zeros([tf.shape(decoder_inputs_z)[0], z_dim])\n",
    "log_var_pz = tf.clip_by_value(log_var_pz, -15.0, 15.0)\n",
    "\n",
    "# Create deterministic layer y\n",
    "samples_y = tf.keras.layers.Dense(units=y_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_h1_')(decoder_inputs_z)\n",
    "\n",
    "grouped_samples_y = []\n",
    "partition_vector_cumsum = np.insert(np.cumsum(y_dim_partition), 0, 0)\n",
    "for i in range(len(types_dict)):\n",
    "    grouped_samples_y.append(samples_y[:, partition_vector_cumsum[i]:partition_vector_cumsum[i+1]])\n",
    "\n",
    "theta = theta_estimation_from_ys(grouped_samples_y, decoder_inputs_s, types_dict, miss_mask)\n",
    "\n",
    "decoder = tf.keras.Model(inputs=[decoder_inputs_s, decoder_inputs_z], outputs=[mean_pz, log_var_pz, theta], name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "in user code:\n\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"Maximum_8:0\", shape=(None, 2), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3e786c1136f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmse_loss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: in user code:\n\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"Maximum_8:0\", shape=(None, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "decoder.compile(optimizer=optimizer, loss=mse_loss_fn)\n",
    "decoder.fit(normalized_data[:, 0:4], [normalized_data[:, 0:4], normalized_data[:, 5:6]], batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_as_feature_list(data, types_dict):\n",
    "    \n",
    "    data_list = []\n",
    "    initial_index = 0\n",
    "    for d in types_dict:\n",
    "        dim = int(d['dim'])\n",
    "        data_list.append(batch_xs[:,initial_index:initial_index+dim])\n",
    "        initial_index += dim\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_evaluation(normalized_data_as_list, types_dict, miss_mask, theta, tau2, normalization_params):\n",
    "    log_p_x = []\n",
    "    log_p_x_missing = []\n",
    "    samples_x = []\n",
    "    params_x = []\n",
    "\n",
    "    #Independet yd -> Compute log(p(xd|yd))\n",
    "    for i,d in enumerate(normalized_data_as_list):\n",
    "        # Select the likelihood for the types of variables\n",
    "        loglik_function = getattr(loglik_models_missing_normalize, 'loglik_' + types_dict[i]['type'])\n",
    "        out = loglik_function([d,miss_mask[:,i]], types_dict[i], theta[i], normalization_params[i], tau2,\n",
    "                                      kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_1_mean_dec_x' + str(i))\n",
    "        log_p_x.append(out['log_p_x'])\n",
    "    return log_p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE as a Model with a custom 'train_step'\n",
    "\n",
    "tau2 = .001\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "        \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape: \n",
    "            log_pi_aux, s, mean_qz, log_var_qz, z = encoder(data)\n",
    "            mean_pz, log_var_pz, theta = decoder([s, z])\n",
    "            reconstruction = mean_pz\n",
    "\n",
    "            # Computing the loss\n",
    "            # KL(q(s|x)||p(s))\n",
    "            log_pi = log_pi_aux\n",
    "            pi_param = tf.nn.softmax(log_pi)\n",
    "            KL_s = -tf.nn.softmax_cross_entropy_with_logits(labels=pi_param, logits=log_pi) + tf.math.log(float(s_dim))\n",
    "            \n",
    "            # KL(q(z|s,x)||p(z|s))\n",
    "            KL_z = -0.5*z_dim + 0.5*tf.reduce_sum(tf.exp(log_var_qz-log_var_pz) + tf.square(mean_pz-mean_qz)/tf.exp(log_var_pz) - log_var_qz + log_var_pz, 1)\n",
    "            \n",
    "            #Eq[log_p(x|y)]\n",
    "            normalized_data_as_list = data_as_feature_list(normalized_data, types_dict)\n",
    "            \n",
    "            log_p_x = loglik_evaluation(normalized_data_as_list, types_dict, miss_mask, theta, tau2, normalization_parameters)\n",
    "\n",
    "            loss_reconstruction = tf.reduce_sum(log_p_x, 0)\n",
    "            \n",
    "            # Complete ELBO \n",
    "            ELBO = tf.reduce_mean(loss_reconstruction - KL_z - KL_s, 0)\n",
    "            \n",
    "        grads = tape.gradient(ELBO, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            'loss': ELBO,\n",
    "            'reconstruction_loss': loss_reconstruction, \n",
    "            'kl_loss': KL_s + KL_Z,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE \n",
    "\n",
    "# (x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "# mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "# mnist_digits = np.expand_dims(mnist_digits, -1).astype('float32')/255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = 'logs/vae/'+datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([699, 92])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-73-9de2919f29e9>:28 train_step\n        normalized_data_as_list = data_as_feature_list(normalized_data, types_dict)\n    <ipython-input-65-d09ba5a48ec6>:7 data_as_feature_list\n        data_list.append(batch_xs[:,initial_index:initial_index+dim])\n\n    NameError: name 'batch_xs' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-77e7f01a9a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: in user code:\n\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\bsankaranarayanan2\\pycharmprojects\\tf_tutorials\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-73-9de2919f29e9>:28 train_step\n        normalized_data_as_list = data_as_feature_list(normalized_data, types_dict)\n    <ipython-input-65-d09ba5a48ec6>:7 data_as_feature_list\n        data_list.append(batch_xs[:,initial_index:initial_index+dim])\n\n    NameError: name 'batch_xs' is not defined\n"
     ]
    }
   ],
   "source": [
    "vae.fit(normalized_data, epochs=5, batch_size=100, callbacks=tensorboard_callback) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function for testing purposes before actually starting the training \n",
    "# Inputs: Raw_data, Normalized_data, miss_list, types_list, batch_size, z_dim, y_dim_output, y_dim_partition, s_dim, tau, tau2, normalization_params\n",
    "\n",
    "samples_test = dict.fromkeys(['s', 'z', 'y', 'x'])\n",
    "test_params = dict()\n",
    "X = tf.concat(X_list, 1)\n",
    "\n",
    "# Create the proposal of q(s|x^o)\n",
    "_, params = s_proposal_multinomial_encoder(X, s_dim, tau)\n",
    "samples_test['s'] = tf.one_hot(tf.argmax(params, 1), depth=s_dim)\n",
    "\n",
    "# Create the proposal of q(z|s,x^o)\n",
    "_, params = z_proposal_GMM_encoder(X, samples_test['s'], z_dim)\n",
    "samples_test['z'] = params[0]\n",
    "\n",
    "# Create deterministic layer y\n",
    "samples_test['y'] = tf.keras.layers.Dense(units=y_dim, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=0.05), name='layer_h1_', reuse=True)\n",
    "grouped_samples_y = y_partition(samples_test['y'], types_list, y_dim_partition)\n",
    "\n",
    "# Compute the parameters h_y\n",
    "theta = theta_estimation_from_ys(grouped_samples_y, samples_test['s'], types_list, miss_list, batch_size, reuse=True)\n",
    "\n",
    "# Compute loglik and output of the VAE\n",
    "log_p_x, log_p_x_missing, samples_test['x'], test_params['x'] = loglik_evaluation(batch_data_list, types_list, miss_list, theta, tau2, normalization_params, reuse=True)\n",
    "\n",
    "# Returns samples_test, test_params, log_p_x, log_p_x_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/vae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
